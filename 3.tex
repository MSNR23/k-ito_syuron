\chapter[剛体1リンクのリンク速度最適化シミュレーション]{剛体1リンクの\\リンク速度最適化\\シミュレーション}

\section{はじめに}
本研究では自作したシミュレータを用いて投擲フォームを導出し、戦略を考察したが、検討に先立ち剛体1リンクモデルでのリンク速度最適化学習を行い、シミュレータと手法の妥当性について検証した。
\section{動力学モデル}
本章の検証で用いた動力学モデルである剛体１リンクを\figref{3.1.jpg}に示す。
\fig{3.1.jpg}{width=.50\hsize}{剛体1リンク}
ラグランジュの方法を用いて導いた剛体1リンクの運動方程式は、次の通りである。\\
各リンクの重心位置$o_{s_{1}}$,$o_{s_{1}}$は、

\begin{eqnarray}
  o_{s} = 
              \begin{bmatrix}
              l_{g}cos\theta\\
              l_{g}sin\theta
              \end{bmatrix}
\end{eqnarray}

微分すると、

\begin{eqnarray}
  o_{\dot{s}} = 
              \begin{bmatrix}
              -l_{g}sin\theta\dot{\theta}\\
              l_{g}cos\theta\dot{\theta}
              \end{bmatrix}
\end{eqnarray}

剛体1リンクの並進運動エネルギー$E_{t}$は、

\begin{eqnarray}
  E_{t} =
  &=&\frac{1}{2}mo_{\dot{s}}{}^T\!o_{\dot{s}} \nonumber \\
  &=&\frac{1}{2}m{l_{g}}^2{\dot{\theta}}^2
\end{eqnarray}

同様に、回転運動エネルギー$E_{k}$は、

\begin{eqnarray}
  E_{r} =
  =\frac{1}{2}I{\dot{\theta}}^2
\end{eqnarray}

よって、運動エネルギー$T$は、

\begin{eqnarray}
  T
  &=&E_{t} + E_{r} \nonumber \\
  &=&\frac{1}{2}{\dot{\theta}}^2(m{l_{g}}^2 + I)
\end{eqnarray}

位置エネルギー$T$は、

\begin{eqnarray}
  U
  = mgl_{g}sin\theta
\end{eqnarray}

ここで、ラグランジュ関数Lを

\begin{eqnarray}
  L
  =T - U
\end{eqnarray}

とすると、運動方程式は、

\begin{eqnarray}
  \equlabel{3.21}
  \frac{d}{dt}(\frac{\partial L}{\partial \dot{q_{i}}}) - \frac{\partial L}{\partial q_{i}} = f_{i} \quad (i = 1,\cdot\cdot\cdot, n)
\end{eqnarray}

ラグランジュ関数Lを求め、\equref{3.21}に代入すると、

\section{シミュレータの作成}
\section{強化学習の設定}
本章の強化学習を行うにあたって、状態、行動、報酬、その他を設定した。
\subsection{状態}
Q学習はQ値をQテーブルと呼ばれる状態と行動で表される表に格納するため、連続値を離散化する必要がある。
状態変数は2つとし、リンクの角度$\theta$と角速度$\dot{\theta}$である。
角度の範囲は-180 deg$\leq$$\theta$$\leq$180 deg、角速度の範囲は-2.0 m/s$\leq$$\dot{\theta}$$\leq$2.0 m/sとした。
また、分割数は各状態4分割であり、全ての状態を$4^{2}$=16通りで表すことができる。
\subsection{行動}
行動は、全3通りに設定した。回転ジョイントにかかるトルク[N]を-1.0、0、+1.0のいずれかを$\varepsilon$-greedt法に基づき選択した。
\subsection{報酬}
報酬の設計について、\equref{rewardA}に示す。
\begin{eqnarray}
  \equlabel{rewardA}
  reward=reward_{scale}\times(\theta_N^2+\dot{\theta}_N^2
  +0.1\times(\theta_{N+1}-\theta_N)^2
  +0.1\times(\dot{\theta}_{N+1}-\dot{\theta}_N)^2)
\end{eqnarray}
\equref{rewardA}において、$\theta_N$は現在のステップのリンクの角度、$\dot{\theta}_N$は現在のステップのリンクの角速度、
$\theta_{N+1}$は1ステップ先のリンクの角度、$\dot{\theta}_{N+1}$は1ステップ先のリンクの角速度である。
また、$reward_{scale}$は報酬スケールを調整するための係数である。本章において、$reward_{scale}$は0.01とした。\\
次に罰則条件ついて、角度が$\theta$>-$\pi/2$または$\pi/2$<$\theta$の範囲にリンクがある際、報酬に-500の罰則を与える設定とした。
この報酬の設計により、リンクの速度が大きいほど報酬が大きくなる。1ステップのリンクの角度、角速度の変化量を2乗することで、
よりリンクの速度に重みを持たせた設計となっている。また、罰則条件の追加により、長時間の罰則範囲での振動を回避するためにリンク速度が大きくなることを期待した。
\subsection{その他}
本検証において、学習率$\alpha$=0.1、割引率$\gamma$=0.9、$\varepsilon$=0.3とした。
また、エピソード数を30、時間ステップdtを0.01、1エピソードあたりのステップ数を6000とし、60秒間の剛体1リンクのリンク速度最適化を行った。
\section{パラメータの設定}
パラメータの設定について、表\tabref{3.1}に示す。
\begin{table}[tb]
  \tablabel{3.1}
  \begin{center}
    \caption{Ragid 1 rink parameters}
    \begin{tabular}{l|c|r}
      \hline
      Parameters & Unit & Values \\
      \hline
      m & kg & 0.14 or 7.24 \\
      l & m & 1.00 \\
      b &  & 0.10 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}
リンクの重さは、砲丸と野球の硬式球を参考に設定した。
\section{シミュレーション検証}

