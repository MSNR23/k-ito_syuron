\chapter[剛体1リンクのリンク速度最適化シミュレーション]{剛体1リンクの\\リンク速度最適化\\シミュレーション}

\section{はじめに}
本章では、自作したシミュレータを用いて強化学習による剛体１リンクのリンク速度最適化を行い、手法の妥当性を検討する。
\section{動力学モデル}
本章の検証で用いた動力学モデルである剛体１リンクを　に示す。
\section{強化学習の設定}
本章の強化学習を行うにあたって、状態、行動、報酬、その他を設定した。
\subsection{状態}
Q学習はQ値をQテーブルと呼ばれる状態と行動で表される表に格納するため、連続値を離散化する必要がある。
状態は、リンクの角度$\theta$[deg]と角速度$\dot{\theta}$[m/s]の２つとし、
角度の範囲は-$\pi$$\leq$$\theta$$\leq$$\pi$、角速度の範囲は-2.0$\leq$$\dot{\theta}$$\leq$2.0とした。
また、分割数は各状態4分割であり、全ての状態を$4^{2}$=16通りで表すことができる。
\subsection{行動}
行動は、全3通りに設定した。回転ジョイントにかかるトルク[N]を-1.0、0、+1.0のいずれかを$\varepsilon$-greedt法に基づき選択した。
\subsection{報酬}
報酬の設計について、\equref{rewardA}に示す。
\begin{eqnarray}
  \equlabel{rewardA}
  reward=reward_{scale}\times(\theta_N^2+\dot{\theta}_N^2
  +0.1\times(\theta_{N+1}-\theta_N)^2
  +0.1\times(\dot{\theta}_{N+1}-\dot{\theta}_N)^2)
\end{eqnarray}
\equref{rewardA}において、$\theta_N$は現在のステップのリンクの角度、$\dot{\theta}_N$は現在のステップのリンクの角速度、
$\theta_{N+1}$は1ステップ先のリンクの角度、$\dot{\theta}_{N+1}$は1ステップ先のリンクの角速度である。
また、$reward_{scale}$は報酬スケールを調整するための係数である。本章において、$reward_{scale}$は0.01とした。\\
次に罰則条件ついて、角度が$\theta$>-$\pi/2$または$\pi/2$<$\theta$の範囲にリンクがある際、報酬に-500の罰則を与える設定とした。
この報酬の設計により、リンクの速度が大きいほど報酬が大きくなる。1ステップのリンクの角度、角速度の変化量を2乗することで、
よりリンクの速度に重みを持たせた設計となっている。また、罰則条件の追加により、長時間の罰則範囲での振動を回避するためにリンク速度が大きくなることを期待した。
\subsection{その他}
本検証において、学習率$\alpha$=0.1、割引率$\gamma$=0.9、$\varepsilon$=0.3とした。
また、エピソード数を30、時間ステップdtを0.01、1エピソードあたりのステップ数を6000とし、60秒間の剛体1リンクのリンク速度最適化を行った。
\section{パラメータの設定}
パラメータの設定について、表\ref{1_link}に示す。
\begin{table}[tb]
  \label{1_link}
  \begin{center}
    \caption{Ragid 1 rink parameters}
    \begin{tabular}{l|c|c|r}
      \hline
      Parameters & Unit & Values \\
      \hline
      m & kg & 0.14 or 7.24 \\
      l & m & 1.00 \\
      b &  & 0.10 \\
      \hline
    \end{tabular}
  \end{center}
\end{table}
リンクの重さは、砲丸と野球の硬式球を参考に設定した。
\section{シミュレーション検証}

